{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABAJO FINAL PROCESAMIENTO DEL LENGUAJE NATURAL \n",
    "ALUMNOS : \n",
    "\n",
    "- ALEJANDRO MADRID GALARZA\n",
    "- ANTONIO JOSÉ LÓPEZ MARTÍNEZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MOTIVACIÓN DEEL TRABAJO\n",
    "Vamos a realizar una aplicacion 'python' en 'jupyter-lab' para la asignatura de Procesamiento del Lenguaje Natural en la que trataremos, con los conocimientos adquiridos en la asignatura así como todo lo que sea necesario para la resolución del mismo, una aplicación que clasifique un conjunto de más de 3500 'tweets' en un clasificador de 11 clases que corresponden a 11 emociones distintas sobre las que clasificaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGAMOS LOS DATOS\n",
    "train_data = pd.read_csv('Data/Train/sem_eval_train_es.csv')\n",
    "test_data = pd.read_csv('Data/Test/sem_eval_test_grupo_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3561, 13), (679, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3561, 12) (679, 1)\n",
      "                                               Tweet  anger  anticipation  \\\n",
      "0  @aliciaenp Ajajjaa somos del clan twitteras pe...  False         False   \n",
      "1  @AwadaNai la mala suerte del gato fichame la c...  False         False   \n",
      "2  @audiomano A mí tampoco me agrado mucho eso. E...   True         False   \n",
      "3  Para llevar a los bebes de un lugar a otro deb...  False         False   \n",
      "4  @DalasReview me encanta la terrible hipocresia...   True         False   \n",
      "\n",
      "   disgust   fear    joy   love  optimism  pessimism  sadness  surprise  trust  \n",
      "0    False  False   True  False     False      False    False     False  False  \n",
      "1    False   True  False  False     False       True    False     False  False  \n",
      "2    False  False  False  False     False      False    False     False  False  \n",
      "3    False  False   True  False     False      False    False     False  False  \n",
      "4     True  False  False  False     False      False    False     False  False  \n",
      "                                               Tweet\n",
      "0  Siguen los amigos que quiero tener, no me pued...\n",
      "1  Baby a veces me hago la enojada solo porque qu...\n",
      "2              @CandeSolsu Callate que sigo ofendida\n",
      "3  Va a tener que pedir perdón por celebrar el dí...\n",
      "4  Domingo, 23:36   Quiero escuchar música y cant...\n"
     ]
    }
   ],
   "source": [
    "# Vamos a eliminar los id's de ambos csv\n",
    "train_data = train_data.drop(['ID'], axis=1)\n",
    "test_data = test_data.drop(['ID'], axis=1)\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos eliminado la columna de ID's de los conjuntos de entrenamiento y testeo tenemos que separar nuestros tweets de testeo que, como podemos observar tiene 12 dimensiones (11 de las diferentes emociones + 1 para los tweets). \n",
    "Los vamos a separar como: \n",
    "- $X=contenido$ $tweets$\n",
    "- $Y=categoría$ $tweet$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3561,) (3561, 11) \n",
      "\n",
      "0    @aliciaenp Ajajjaa somos del clan twitteras pe...\n",
      "1    @AwadaNai la mala suerte del gato fichame la c...\n",
      "2    @audiomano A mí tampoco me agrado mucho eso. E...\n",
      "3    Para llevar a los bebes de un lugar a otro deb...\n",
      "4    @DalasReview me encanta la terrible hipocresia...\n",
      "Name: Tweet, dtype: object \n",
      "\n",
      "   anger  anticipation  disgust   fear    joy   love  optimism  pessimism  \\\n",
      "0  False         False    False  False   True  False     False      False   \n",
      "1  False         False    False   True  False  False     False       True   \n",
      "2   True         False    False  False  False  False     False      False   \n",
      "3  False         False    False  False   True  False     False      False   \n",
      "4   True         False     True  False  False  False     False      False   \n",
      "\n",
      "   sadness  surprise  trust  \n",
      "0    False     False  False  \n",
      "1    False     False  False  \n",
      "2    False     False  False  \n",
      "3    False     False  False  \n",
      "4    False     False  False  \n"
     ]
    }
   ],
   "source": [
    "X_train = train_data['Tweet']\n",
    "y_train = train_data.drop(['Tweet'], axis=1)\n",
    "print(X_train.shape, y_train.shape, '\\n')\n",
    "print(X_train.head(), '\\n')\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora vamos a comanzar con el preprocesado de los datos\n",
    "Ahora solo vamos a trabajar con el conjunto de entrenamiento ya que tenemos que masticar los datos y pasárselos al modelo que posteriormente entrenamremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos el preprocesado\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
